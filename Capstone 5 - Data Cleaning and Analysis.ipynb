{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jkovach/opt/anaconda3/lib/python3.7/site-packages/tqdm/std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      " 78%|███████▊  | 683/875 [17:21<03:57,  1.24s/it]"
     ]
    }
   ],
   "source": [
    "#! Python3\n",
    "# by Jacob Kovach\n",
    "# Confidential and Proprietary\n",
    "\n",
    "import numpy as np, pandas as pd, urllib.request, spacy, re, os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import tokenize\n",
    "from pandas_datareader import DataReader\n",
    "from collections import Counter\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "tqdm.pandas()\n",
    "\n",
    "earnings_df = pd.read_csv('/Users/jkovach/Downloads/earnings-call-transcripts/_raw_data.csv')\n",
    "earnings_df = earnings_df.drop('Unnamed: 0', 1)\n",
    "\n",
    "def clean_and_tokenize(ts):\n",
    "    ts = re.sub(r'\\d+', '', ts)\n",
    "    ts_doc = nlp(ts)\n",
    "    return ts_doc\n",
    "    #content = re.sub(r'[A-Z]+', '', content)\n",
    "\n",
    "earnings_df['Tokens'] = earnings_df['transcript'].progress_apply(clean_and_tokenize)\n",
    "\n",
    "earnings_df.head()\n",
    "\n",
    "# Create single text file and run NLP tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 200 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(200)]\n",
    "\n",
    "# get set amount of words\n",
    "common_words = []\n",
    "for i in range(earnings_df.shape[0]):\n",
    "    cw = bag_of_words(earnings_df.loc[i, 'Tokens'])\n",
    "    common_words = set(list(common_words) + cw)\n",
    "    \n",
    "print(len(common_words))\n",
    "print(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['Tokens'] = sentences['Tokens']\n",
    "    df['Movement'] = sentences['Movement']\n",
    "    df.loc[:, common_words] = 0\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, transcript in enumerate(df['Tokens']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in transcript\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        #print(words)\n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 50 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "word_counts = bow_features(earnings_df, common_words)\n",
    "word_counts.head()\n",
    "\n",
    "# Word to vec, get "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "y = word_counts['Movement']\n",
    "X = np.array(word_counts.drop(['Tokens','Movement'], 1))\n",
    "\n",
    "print(\"Class Balance: {}\".format(sorted(Counter(y).items())))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "train = rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression() \n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', clf.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
